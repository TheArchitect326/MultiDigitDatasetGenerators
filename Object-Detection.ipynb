{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digit_Detection-Dataset.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz611y66_vB-"
      },
      "source": [
        "import os\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from fastai.vision import *\n",
        "from fastai.vision.all import *\n",
        "from glob import glob\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVb99PkNIbLW"
      },
      "source": [
        "def find_compontents(img):\n",
        "  '''Returns the positions of each image component'''\n",
        "  grey = 255 - cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  _, thresh = cv2.threshold(grey, 0, 255, cv2.THRESH_OTSU)\n",
        "  stats = cv2.connectedComponentsWithStats(thresh)[2]\n",
        "  return stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR7hL8T5_a9P"
      },
      "source": [
        "def annotations(img, n):\n",
        "  '''Returns an array of annotations (in format:\n",
        "  [[x1, y1, x2, y2], digit]) given an image of a number.'''\n",
        "  stats = find_compontents(img)\n",
        "  bg_label = np.argmax(stats[:, 4])\n",
        "\n",
        "  bboxes = [data[1][:4] for data in enumerate(stats) if data[0] != bg_label]\n",
        "  bboxes = np.array(sorted(bboxes, key=lambda k: k[1])).astype(int)\n",
        "\n",
        "  new_format = bboxes\n",
        "\n",
        "  new_format[:, 0] = bboxes[:, 0]\n",
        "  new_format[:, 1] = bboxes[:, 1]\n",
        "  new_format[:, 2] = bboxes[:, 0] + bboxes[:, 2]\n",
        "  new_format[:, 3] = bboxes[:, 1] + bboxes[:, 3]\n",
        "\n",
        "  return np.array(list(zip(new_format, str(n))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwxQYoSNWORh"
      },
      "source": [
        "def filename_to_info(filename):\n",
        "  name = filename.split('/')[-1].split('.')[0]\n",
        "  n = int(name.split('.')[-1])\n",
        "\n",
        "  return n, name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYUNGwM6YGnP"
      },
      "source": [
        "def create_dataset_from_images(name, in_path, out_path=None, fname_fn=None, size=None):\n",
        "  '''Creates an object detection dataset given a directory and a filename function'''\n",
        "  if not out_path:\n",
        "    out_path = f'{in_path}/{name}'\n",
        "  if not fname_fn:\n",
        "    fname_fn = filename_to_info\n",
        "  if not size:\n",
        "    size = (250, 150)\n",
        "\n",
        "  images, i = get_image_files(in_path), 0\n",
        "\n",
        "  for filename in images:\n",
        "    try:\n",
        "      n, name = fname_fn(filename)\n",
        "\n",
        "      img = cv2.imread(filename)\n",
        "      img = cv2.resize(img, (250, 150))\n",
        "      data = annotations(img, n)\n",
        "\n",
        "      cv2.imwrite(f'{out_path}/{name}.png', img)\n",
        "      np.save(f'{out_path}/{name}.npy', data)\n",
        "\n",
        "    except Exception as e:\n",
        "      i += 1\n",
        "      print(f'Skipped: {filename} due to {e}')\n",
        "\n",
        "  print(f'Total images skipped: {i}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}